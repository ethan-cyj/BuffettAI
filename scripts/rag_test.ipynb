{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain_core.documents import Document\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "def safe_load_pickle(file_path: str) -> Any:\n",
    "    \"\"\"Safely load pickle files that may contain pandas objects\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        try:\n",
    "            # First try standard pickle load\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                return pickle.load(f)\n",
    "        except (TypeError, AttributeError, pickle.UnpicklingError):\n",
    "            try:\n",
    "                # Fallback to pandas read_pickle\n",
    "                return pd.read_pickle(file_path)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Failed to load {file_path}: {str(e)}\")\n",
    "\n",
    "def inspect_file(file_path: str) -> None:\n",
    "    \"\"\"Debug function to examine file structure\"\"\"\n",
    "    print(f\"\\n=== Inspecting {file_path} ===\")\n",
    "    try:\n",
    "        if file_path.endswith(('.xlsx', '.xls')):\n",
    "            df = pd.read_excel(file_path)\n",
    "            print(\"Excel file detected\")\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "            print(\"Columns:\", df.columns.tolist())\n",
    "            print(\"\\nFirst row:\")\n",
    "            pprint(df.iloc[0].to_dict())\n",
    "        elif file_path.endswith('.pkl'):\n",
    "            data = safe_load_pickle(file_path)\n",
    "            print(f\"Type: {type(data)}\")\n",
    "            if isinstance(data, pd.DataFrame):\n",
    "                print(\"Pandas DataFrame detected\")\n",
    "                print(f\"Shape: {data.shape}\")\n",
    "                print(\"Columns:\", data.columns.tolist())\n",
    "                print(\"\\nFirst row:\")\n",
    "                pprint(data.iloc[0].to_dict())\n",
    "            elif isinstance(data, list):\n",
    "                print(f\"List of {len(data)} items\")\n",
    "                if data:\n",
    "                    print(\"\\nFirst item type:\", type(data[0]))\n",
    "                    if isinstance(data[0], dict):\n",
    "                        print(\"Keys in first item:\", data[0].keys())\n",
    "            elif isinstance(data, dict):\n",
    "                print(\"Dictionary with keys:\", data.keys())\n",
    "            else:\n",
    "                print(\"Content sample:\", str(data)[:200] + \"...\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format\")\n",
    "    except Exception as e:\n",
    "        print(f\"Inspection failed: {str(e)}\")\n",
    "\n",
    "def load_buffet_qna_xlsx(file_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load Q&A data from Excel with columns: Section, Questions, Answers\n",
    "    Returns List[Document] where:\n",
    "    - page_content contains formatted Q&A\n",
    "    - metadata contains structured fields\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Validate required columns\n",
    "    required_cols = {'Section', 'Questions', 'Answers'}\n",
    "    missing = required_cols - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in Q&A file: {missing}\")\n",
    "\n",
    "    documents = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Create human-readable content\n",
    "        page_content = (\n",
    "            f\"Question: {row['Questions']}\\n\"\n",
    "            f\"Answer: {row['Answers']}\\n\"\n",
    "            f\"Section: {row['Section']}\"\n",
    "        )\n",
    "        \n",
    "        # Store structured data in metadata\n",
    "        metadata = {\n",
    "            \"section\": row[\"Section\"],\n",
    "            \"question\": row[\"Questions\"],\n",
    "            \"answer\": row[\"Answers\"],\n",
    "            \"source\": \"buffet_qna\"\n",
    "        }\n",
    "        \n",
    "        documents.append(Document(\n",
    "            page_content=page_content,\n",
    "            metadata=metadata\n",
    "        ))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def load_brka_trades_xlsx(file_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load trades data from Excel with financial columns\n",
    "    Returns List[Document] where:\n",
    "    - page_content contains key trade info\n",
    "    - metadata contains all raw data\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Validate required columns\n",
    "    required_cols = {'RIC', 'Security Name', 'Date', 'Position', 'Position Change'}\n",
    "    missing = required_cols - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in trades file: {missing}\")\n",
    "\n",
    "    documents = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Create human-readable summary\n",
    "        page_content = (\n",
    "            f\"Security: {row['Security Name']} ({row['RIC']})\\n\"\n",
    "            f\"Date: {row['Date']}\\n\"\n",
    "            f\"Position: {row['Position']:,} shares\\n\"\n",
    "            f\"Change: {row['Position Change']:+,}\"\n",
    "        )\n",
    "        \n",
    "        # Store all raw data in metadata\n",
    "        metadata = row.to_dict()\n",
    "        metadata.update({\"source\": \"brka_trades\"})\n",
    "        \n",
    "        documents.append(Document(\n",
    "            page_content=page_content,\n",
    "            metadata=metadata\n",
    "        ))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def load_news_pickle(file_path: str) -> List[Document]:\n",
    "    \"\"\"Load news pickle with flexible format handling\"\"\"\n",
    "    data = safe_load_pickle(file_path)\n",
    "    \n",
    "    # Handle DataFrame case\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        data = data.to_dict('records')\n",
    "    \n",
    "    # Handle list of dicts\n",
    "    if isinstance(data, list) and all(isinstance(x, dict) for x in data):\n",
    "        return [\n",
    "            Document(\n",
    "                page_content=item.get('text', item.get('content', str(item))),\n",
    "                metadata={k: v for k, v in item.items() \n",
    "                         if k not in ['text', 'content']}\n",
    "            )\n",
    "            for item in data\n",
    "        ]\n",
    "    \n",
    "    # Handle single dictionary\n",
    "    elif isinstance(data, dict):\n",
    "        return [Document(\n",
    "            page_content=data.get('text', data.get('content', str(data))),\n",
    "            metadata={k: v for k, v in data.items() \n",
    "                     if k not in ['text', 'content']}\n",
    "        )]\n",
    "    \n",
    "    # Fallback for other formats\n",
    "    return [Document(page_content=str(data))]\n",
    "\n",
    "def load_shareholder_letters_pickle(file_path: str) -> List[Document]:\n",
    "    \"\"\"Load shareholder letters with year-based structure\"\"\"\n",
    "    data = safe_load_pickle(file_path)\n",
    "    \n",
    "    if isinstance(data, dict) and all(isinstance(k, (str, int)) for k in data):\n",
    "        return [\n",
    "            Document(\n",
    "                page_content=content,\n",
    "                metadata={\"year\": year, \"source\": \"shareholder_letter\"}\n",
    "            )\n",
    "            for year, content in data.items()\n",
    "        ]\n",
    "    \n",
    "    # Fallback for other formats\n",
    "    return load_news_pickle(file_path)\n",
    "\n",
    "def load_documents(file_path: str) -> List[Document]:\n",
    "    \"\"\"Main document loading interface\"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.xlsx'):\n",
    "            if 'buffet_qna' in file_path.lower():\n",
    "                return load_buffet_qna_xlsx(file_path)\n",
    "            elif 'brka_trades' in file_path.lower():\n",
    "                return load_brka_trades_xlsx(file_path)\n",
    "        \n",
    "        elif file_path.endswith('.pkl'):\n",
    "            if 'news' in file_path.lower():\n",
    "                return load_news_pickle(file_path)\n",
    "            elif 'shareholder' in file_path.lower():\n",
    "                return load_shareholder_letters_pickle(file_path)\n",
    "        \n",
    "        raise ValueError(f\"Unrecognized file type: {file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {str(e)}\")\n",
    "        return [Document(\n",
    "            page_content=f\"Error loading document: {str(e)}\",\n",
    "            metadata={\"source\": \"error\", \"file_path\": file_path}\n",
    "        )]\n",
    "\n",
    "def load_all_documents(\n",
    "    base_path: str = \"/data\",\n",
    "    buffet_qna_path: Optional[str] = None,\n",
    "    brka_trades_path: Optional[str] = None,\n",
    "    news_path: Optional[str] = None,\n",
    "    shareholder_letters_path: Optional[str] = None,\n",
    "    verbose: bool = True\n",
    ") -> List[Document]:\n",
    "    \"\"\"\n",
    "    Load all 4 document sources at once.\n",
    "    \n",
    "    Args:\n",
    "        base_path: Base directory for files if individual paths not specified\n",
    "        *_path: Override individual file paths\n",
    "        verbose: Print loading progress\n",
    "    \n",
    "    Returns:\n",
    "        Combined list of Documents from all sources\n",
    "    \"\"\"\n",
    "    # Set default paths if not specified\n",
    "    buffet_qna_path = buffet_qna_path or Path(base_path) / \"buffet_qna.xlsx\"\n",
    "    brka_trades_path = brka_trades_path or Path(base_path) / \"brka_trades.xlsx\"\n",
    "    news_path = news_path or Path(base_path) / \"news.pkl\"\n",
    "    shareholder_letters_path = shareholder_letters_path or Path(base_path) / \"shareholder_letters.pkl\"\n",
    "    \n",
    "    all_docs = []\n",
    "    \n",
    "    # Load each file with progress reporting\n",
    "    for file_path, loader in [\n",
    "        (buffet_qna_path, load_buffet_qna_xlsx),\n",
    "        (brka_trades_path, load_brka_trades_xlsx),\n",
    "        (news_path, load_news_pickle),\n",
    "        (shareholder_letters_path, load_shareholder_letters_pickle)\n",
    "    ]:\n",
    "        try:\n",
    "            if verbose:\n",
    "                print(f\"Loading {file_path}...\")\n",
    "            docs = loader(file_path)\n",
    "            all_docs.extend(docs)\n",
    "            if verbose:\n",
    "                print(f\"Loaded {len(docs)} documents\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error loading {file_path}: {str(e)}\")\n",
    "            all_docs.append(Document(\n",
    "                page_content=f\"Error loading {file_path}: {str(e)}\",\n",
    "                metadata={\"source\": \"error\", \"file_path\": str(file_path)}\n",
    "            ))\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nTotal documents loaded: {len(all_docs)}\")\n",
    "    \n",
    "    return all_docs\n",
    "\n",
    "# print(f\"Script running from: {os.getcwd()}\")\n",
    "\n",
    "# print(load_documents(\"../data/news.pkl\"))\n",
    "# print(load_all_documents(\"../data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "CHUNK_SIZE = 1024\n",
    "CHUNK_OVERLAP = 20\n",
    "\n",
    "def split_documents(documents):\n",
    "    \"\"\"\n",
    "    Splits a list of document objects into manageable text chunks.\n",
    "    Assumes each document has a 'content' field.\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "    # For compatibility with langchain's splitter, wrap your dicts in a simple object:\n",
    "    # Here we assume each document is a dict with a 'content' key.\n",
    "    # You might need to convert these dicts to the Document type expected by langchain.\n",
    "    return splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "# Compare 2 different retrieval methods and evaluate\n",
    "\n",
    "def build_bm25(corpus):\n",
    "    \"\"\"\n",
    "    Builds a BM25 model from a list of texts (corpus).\n",
    "    \"\"\"\n",
    "    return BM25Okapi(corpus)\n",
    "\n",
    "def build_faiss_index(documents):\n",
    "    \"\"\"\n",
    "    Uses OpenAI embeddings to build a FAISS vectorstore from documents.\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # FAISS vectorstore will build the index based on document 'content'\n",
    "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "def create_ensemble_retriever(bm25_retriever, faiss_retriever):\n",
    "    \"\"\"\n",
    "    Combines BM25 and FAISS retrievers into an ensemble retriever.\n",
    "    \"\"\"\n",
    "    return EnsembleRetriever(retrievers=[bm25_retriever, faiss_retriever])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# Initialize the pre-trained cross-encoder (adjust model name as needed)\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "def rerank_documents(query, documents, top_k=5):\n",
    "    \"\"\"\n",
    "    Reranks a list of document objects based on relevance to the query.\n",
    "    Each document is assumed to have a 'content' field.\n",
    "    \"\"\"\n",
    "    pairs = [[query, doc[\"content\"]] for doc in documents]\n",
    "    scores = cross_encoder.predict(pairs)\n",
    "    ranked_indices = np.argsort(scores)[::-1][:top_k]\n",
    "    return [documents[i] for i in ranked_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(company_name: str, documents):\n",
    "    \"\"\"\n",
    "    Creates a prompt for the LLM using the retrieved documents.\n",
    "    Assumes each document is a dict with a 'content' field.\n",
    "    \"\"\"\n",
    "    context = \"\\n\".join([doc[\"content\"] for doc in documents])\n",
    "    prompt = f\"\"\"\n",
    "You are a financial analyst tasked with generating an investment report. Use the following context:\n",
    "{context}\n",
    "\n",
    "Focus on revenue growth, profitability, and initiatives.\n",
    "Provide specific numbers and facts where available.\n",
    "Use a professional, concise tone.\n",
    "Structure the report with these sections:\n",
    "- Overview\n",
    "- Revenue Growth\n",
    "- Profitability\n",
    "- ESG Initiatives\n",
    "- Conclusion\n",
    "\n",
    "Investment Report for {company_name}:\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def create_evaluation_prompt(query: str, generated_report: str, retrieved_documents):\n",
    "    \"\"\"\n",
    "    Creates an evaluation prompt for the LLM to judge the generated report.\n",
    "    \"\"\"\n",
    "    retrieved_context = \"\\n\".join([doc[\"content\"] for doc in retrieved_documents])\n",
    "    prompt = f\"\"\"\n",
    "You are an expert financial analyst evaluating an investment report.\n",
    "    \n",
    "Query:\n",
    "{query}\n",
    "\n",
    "Generated Report:\n",
    "{generated_report}\n",
    "\n",
    "Retrieved Context:\n",
    "{retrieved_context}\n",
    "\n",
    "Evaluation Criteria:\n",
    "1. Relevance (0-10): Does the report address the query?\n",
    "2. Accuracy (0-10): Are the facts correct and supported by the retrieved context?\n",
    "3. Coherence (0-10): Is the report well-structured and easy to understand?\n",
    "\n",
    "Provide a score for each criterion along with a brief explanation.\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai \n",
    "from rag.text_splitter import split_documents\n",
    "from rag.retrieval import build_bm25, build_faiss_index, create_ensemble_retriever\n",
    "from rag.reranker import rerank_documents\n",
    "from rag.prompt_engineering import create_prompt, create_evaluation_prompt\n",
    "\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# load env variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# set OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"API key is not set\")\n",
    "\n",
    "# call custom LLM\n",
    "def call_custom_llm(prompt: str, context: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Placeholder function to call your custom LLM (@ethan, @yucai)\n",
    "    The function should take a prompt and optional context, then return a generated text.\n",
    "    In production, replace this with the actual API call or function to your LLM.\n",
    "    \"\"\"\n",
    "    # For demonstration, we simply return the prompt combined with context.\n",
    "    # Replace this with your actual generation call.\n",
    "    combined_input = context + \"\\n\" + prompt if context else prompt\n",
    "    return \"Custom LLM Response based on:\\n\" + combined_input\n",
    "\n",
    "class RAGPipeline:\n",
    "    def __init__(self, raw_documents):\n",
    "        \"\"\"\n",
    "        Initializes the pipeline:\n",
    "         - Splits raw documents into text chunks.\n",
    "         - Builds BM25 and FAISS retrievers.\n",
    "         - Combines them into an ensemble retriever.\n",
    "         - Initializes a context memory for feedback loop.\n",
    "        Expects raw_documents as a list of dicts with at least a 'content' field.\n",
    "        \"\"\"\n",
    "        # Split documents into chunks.\n",
    "        self.documents = split_documents(raw_documents)\n",
    "        \n",
    "        # Build BM25 retriever.\n",
    "        corpus = [doc.page_content for doc in self.documents]  \n",
    "\n",
    "        bm25_model = build_bm25(corpus)\n",
    "        \n",
    "        self.bm25_retriever = BM25Retriever.from_documents(self.documents)\n",
    "        self.bm25_retriever.k = 5\n",
    "        \n",
    "        # Build FAISS retriever.\n",
    "        faiss_vectorstore = build_faiss_index(self.documents)\n",
    "        self.faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "        \n",
    "        # Create an ensemble retriever.\n",
    "        self.ensemble_retriever = create_ensemble_retriever(self.bm25_retriever, self.faiss_retriever)\n",
    "        \n",
    "        # Initialize context memory for feedback loop (stores conversation history).\n",
    "        self.context_memory = []\n",
    "\n",
    "    def retrieve_and_rerank(self, query: str, retriever, top_k: int = 5):\n",
    "        \"\"\"\n",
    "        Retrieves documents using the provided retriever and then reranks them.\n",
    "        \"\"\"\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        return rerank_documents(query, docs, top_k=top_k)\n",
    "    \n",
    "    def generate_report(self, query: str, company_name: str, retriever):\n",
    "        \"\"\"\n",
    "        Retrieves documents, creates a prompt, adds context from previous interactions,\n",
    "        and uses the custom LLM to generate a report.\n",
    "        \"\"\"\n",
    "        # Retrieve and rerank documents.\n",
    "        retrieved_docs = self.retrieve_and_rerank(query, retriever)\n",
    "        \n",
    "        # Create the base prompt using the retrieved documents.\n",
    "        prompt = create_prompt(company_name, retrieved_docs)\n",
    "        \n",
    "        # Incorporate feedback context (if any) into the prompt.\n",
    "        # Here we simply concatenate the context memory into a single string.\n",
    "        context_text = \"\\n\".join(self.context_memory)\n",
    "        \n",
    "        # Call your custom LLM with the prompt and context.\n",
    "        report = call_custom_llm(prompt, context=context_text)\n",
    "        \n",
    "        # Update context memory: you can choose to store just the query/response pair\n",
    "        # or additional details. Here, we store the generated report.\n",
    "        self.context_memory.append(f\"User Query: {query}\")\n",
    "        self.context_memory.append(f\"LLM Report: {report}\")\n",
    "        \n",
    "        return report, retrieved_docs\n",
    "\n",
    "    def evaluate_report(self, query: str, report: str, retrieved_docs):\n",
    "        \"\"\"\n",
    "        Uses the custom LLM (or another LLM) to evaluate the generated report.\n",
    "        This function calls the evaluation prompt and returns the evaluation.\n",
    "        \"\"\"\n",
    "        eval_prompt = create_evaluation_prompt(query, report, retrieved_docs)\n",
    "        # You could also use your custom LLM here, but for now, we call the placeholder.\n",
    "        evaluation = call_custom_llm(eval_prompt)\n",
    "        return evaluation\n",
    "\n",
    "    def process_query(self, query: str, company_name: str, method: str = \"ensemble\"):\n",
    "        \"\"\"\n",
    "        Processes the query using one of the retrieval methods:\n",
    "          - \"bm25\": BM25 only.\n",
    "          - \"faiss\": FAISS only.\n",
    "          - \"ensemble\": Ensemble (BM25 + FAISS).\n",
    "        Returns the generated report and its evaluation.\n",
    "        \"\"\"\n",
    "        if method == \"bm25\":\n",
    "            retriever = self.bm25_retriever\n",
    "        elif method == \"faiss\":\n",
    "            retriever = self.faiss_retriever\n",
    "        else:\n",
    "            retriever = self.ensemble_retriever\n",
    "        \n",
    "        report, retrieved_docs = self.generate_report(query, company_name, retriever)\n",
    "        evaluation = self.evaluate_report(query, report, retrieved_docs)\n",
    "        return report, evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document loading\n",
    "if args.load_all:\n",
    "    print(\"Loading all standard documents from data/ directory...\")\n",
    "    raw_docs = load_all_documents(base_path=\"../data\")\n",
    "else:\n",
    "    raw_docs = load_documents(args.data_path)\n",
    "\n",
    "# Initialize and run pipeline\n",
    "pipeline = RAGPipeline(raw_docs)\n",
    "report, evaluation = pipeline.process_query(\n",
    "    args.query, args.company, method=args.method\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
