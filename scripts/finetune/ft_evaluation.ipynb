{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethan/Documents/GitHub/BuffettAI/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForCausalLM\n",
    ")\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"oopere-FinChat-XS\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"oopere/FinChat-XS\")\n",
    "buffetAI = AutoModelForCausalLM.from_pretrained(\"oopere-FinChat-XS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['The Investment Industry', 'Technology', 'Education', 'Gold'], dtype='object', name='Section')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/buffet_qna_finetune_ready.csv')\n",
    "df = df.dropna()\n",
    "\n",
    "# Identify rare classes\n",
    "class_counts = df['Section'].value_counts()\n",
    "rare_classes = class_counts[class_counts < 11].index\n",
    "print(rare_classes)\n",
    "\n",
    "# Combine rare classes into 'Other'\n",
    "df['Section'] = df['Section'].replace(rare_classes, 'Other')\n",
    "\n",
    "# Update Section_code after modification\n",
    "df['Section'] = df['Section'].astype('category')\n",
    "df['Section_code'] = df['Section'].cat.codes\n",
    "\n",
    "df['Section'] = df['Section'].astype('category')\n",
    "df['Section_code'] = df['Section'].cat.codes\n",
    "\n",
    "# Split the dataset into training, validation, and test sets, proportionately by Sections column\n",
    "# This will ensure that each split has a similar distribution of the Sections column\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.05, stratify=df['Section_code'], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['Section_code'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Normal Response----------\n",
      "system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face\n",
      "user\n",
      "Question: Do you have any investing tips?\n",
      "Answer:\n",
      "assistant\n",
      "Investment advice can be obtained from various resources. The most common ones include the FINRA Investor Education Foundation and NerdWallet's Investing for Beginners section of their website. Other sources may also provide useful information on investment strategies that could help one achieve financial stability. \n",
      "\n",
      "It is important to consult with an expert such as your own financial advisor or someone who has experience in finance before making decisions about investments. It would not only benefit you but others too if everyone had access to reliable sources which advise accordingly without causing unnecessary harm. \n",
      "Additionally, there should always consider how much risk one wants to take on when deciding what type of stocks they want to invest in. One must ensure it doesnt compromise future goals based solely off this single factor at hand. Always keep up-to-date knowledge so you will stay ahead of trends hence being able to adapt wisely.  \n",
      "Remember that no matter how well planned something goes wrong sometimes happens; therefore we must learn from mistakes and move forward every time! This way you won't regret anything once again while trying to make smart choices through these steps. Be sure to review regularly whether things go as expected or differently than initially thought.\n",
      "I recommend consulting your local stockbroker or using online tools like\n",
      "----------BuffetAI Response----------\n",
      "system\n",
      "You are a helpful AI assistant named SmolLM, trained by Hugging Face\n",
      "user\n",
      "Question: Do you have any investing tips?\n",
      "Answer:\n",
      "assistant\n",
      "No investment advice - I don't know what's in your head. You should always do your own research and be smart about it. Don’t buy anything that doesn’t make sense to you; if something sounds too good to pass up – but is just an idea or hearsay from someone else – then run away fast! It may sound like common-sense wisdom today but tomorrow it will not work out as expected. Always evaluate things before making money decisions. And never sell because the price goes down. Just keep buying more until you get back on top of everything. Enjoy life – there isn’t much upside after 50. If you start doing this at age 21, you can live forever. The universe has given us enough for our time here so why would we want to spend all of it chasing money when we could enjoy being alive instead? There is no such thing as a bad stock market day. Every great business turns into one big deal every now and again. All businesses need some upsides over their lifetime, though they usually won’t last long. This applies to both stocks and bonds (and even real estate). Investments are going to happen anyway, so focus on finding those opportunities where you really believe you\n"
     ]
    }
   ],
   "source": [
    "def buffett_answer(question, max_new_tokens=256):\n",
    "    prompt = f\"Question: {question}\\nAnswer:\"\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]   \n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(base_model.device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = base_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.7,\n",
    "            repetition_penalty=1.2,\n",
    "            eos_token_id=tokenizer.eos_token_id,  # clearly defined stop token\n",
    "            pad_token_id=tokenizer.eos_token_id   # to handle padding gracefully\n",
    "        )\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(buffetAI.device)\n",
    "    with torch.no_grad():\n",
    "        buffet_output_ids = buffetAI.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.7,\n",
    "            repetition_penalty=1.2,\n",
    "            eos_token_id=tokenizer.eos_token_id,  # clearly defined stop token\n",
    "            pad_token_id=tokenizer.eos_token_id   # to handle padding gracefully\n",
    "        )\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True), tokenizer.decode(buffet_output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Try it\n",
    "test_q = \"How should I think about investing during a recession?\"\n",
    "test_q = \"Do you have any investing tips?\"\n",
    "base_response, buffet_response = buffett_answer(test_q)\n",
    "print(\"-\"* 10 + \"Normal Response\" + \"-\"*10)\n",
    "print(base_response)\n",
    "print(\"-\"* 10 + \"BuffetAI Response\" + \"-\"*10)\n",
    "print(buffet_response)\n",
    "# \"Question: How should I think about investing during a recession? \n",
    "#  Answer: I focus on companies with strong fundamentals...\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "base_preds = []\n",
    "buffet_preds = []\n",
    "references = []\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    question = row['Questions']\n",
    "    reference = row['Answers']\n",
    "\n",
    "    base_resp, buffet_resp = buffett_answer(question)\n",
    "    \n",
    "    # Append generated and reference responses\n",
    "    base_preds.append(base_resp.replace(f\"Question: {question}\\nAnswer:\", \"\").strip())\n",
    "    buffet_preds.append(buffet_resp.replace(f\"Question: {question}\\nAnswer:\", \"\").strip())\n",
    "    references.append([reference.strip()])  # BLEU expects list of references per prediction\n",
    "\n",
    "#save the preds\n",
    "base_preds_df = pd.DataFrame(base_preds, columns=[\"Base_Predictions\"])\n",
    "buffet_preds_df = pd.DataFrame(buffet_preds, columns=[\"Buffet_Predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "# Load BLEU metric\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "\n",
    "# Compute BLEU scores\n",
    "base_bleu = bleu.compute(predictions=base_preds, references=references)\n",
    "buffet_bleu = bleu.compute(predictions=buffet_preds, references=references)\n",
    "\n",
    "# Show results\n",
    "print(\"Base Model BLEU Score:\", base_bleu[\"bleu\"])\n",
    "print(\"BuffetAI BLEU Score:\", buffet_bleu[\"bleu\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
